# STAGE 10 — BASELINE HUMAN VISIBILITY

**First Stable Search Placement**

From The 11-Stage AI Visibility Lifecycle (v0.7)

Bernard Lynch | AI Visibility Architecture Group Limited

---

> This document is a mirror of the canonical publication hosted on Zenodo. The authoritative version of record is the Zenodo DOI: [10.5281/zenodo.18514176](https://doi.org/10.5281/zenodo.18514176) In the event of any discrepancy, the Zenodo version prevails.

**Methodology Note**

This analysis is based on systematic observation of AI baseline ranking behavior across multiple platforms

(Google AI, ChatGPT, Claude, Perplexity, Gemini), empirical testing through CV4Students—a non-

commercial educational platform with verified AI visibility across 125+ countries—and technical

understanding of how large language models transition domains from experimental visibility to stable

placement, measure behavioral consistency at scale, and validate sustained performance before enabling

growth.

Baseline ranking mechanisms described represent structural analysis of when AI systems shift from

controlled testing to repeatable visibility, how they establish initial competitive positioning, and what

criteria determine progression to growth visibility. Timeline estimates reflect observable patterns in

stabilization periods.

**Quick Overview**

**Stage 10 — Baseline Human Ranking** — is where a domain achieves its first stable placement in human-

facing discovery systems.

After surviving early human visibility testing in Stage 9, AI systems begin allowing a domain to appear

consistently—not experimentally—within search results, AI-generated answers, or hybrid discovery

interfaces.

This stage does not confer prominence.

It does not imply authority.

It does not signal success.

**It establishes repeatable visibility under controlled expectations.**

**Critical Context: From Testing to ParticipationCritical Context: From Testing to Participation**

Everything before Stage 10 has been provisional.

Even when humans were exposed to the domain in Stage 9, that exposure was limited, reversible, and

experimental. **Stage 10 is different.**

At this point, the system decides:

**\"This domain can now be placed predictably without causing harm.\"**

That decision marks the transition from testing to baseline participation in the visible knowledge ecosystem.

**Stage 10 represents the formal transition from \"testing\" to \"participation.\"**

The site is no longer a micro-experiment (Stage 9). It is now:

Visible

Stable

Competitive

Ranking against real websites

Affecting real user journeys

**If Stage 9 performance was the small-scale lab test, Stage 10 is the real-world pilot rollout.**

**Survival Rates: The Activation Moment**

Based on observable patterns across AI system behavior:

Out of 100 websites:

**\~90 pass Stage 1** (basic crawling and access)

**\~70-80 pass Stage 2** (semantic ingestion)

**\~60-70 pass Stage 3** (classification without fatal ambiguity)

**\~50-60 pass Stage 4** (internal harmony checks)

**\~30-50 pass Stage 5** (the \"comprehension barrier\")

**\~20-35 complete Stage 6** (trust building over time)

**\~5-15 pass Stage 7** (the \"trust barrier\")

**\~3-10 pass Stage 8** (competitive readiness assessment)

**\~2-7 pass Stage 9** (early human visibility testing)

**\~1-5 establish Stage 10** (baseline ranking)

**\~1-3 reach Stage 11** (growth visibility)

**Baseline ranking is not top-page ranking.** It is the initial placement tier where AI gives the domain afoothold in the human-visible SERP ecosystem.

This stage answers: \"How should this domain be positioned in real search results so that humans benefit

without risking user disorientation or poor satisfaction?\"

**Baseline ranking is not growth—it is activation.**

The site now exists inside the human-visible ecosystem.

**What \"Baseline Ranking\" Actually Means**

Baseline ranking is not competitive dominance.

It is not page-one placement.

It is not preferential treatment.

It is not growth.

**In practical terms, baseline ranking means:**

The domain appears consistently for certain queries

Placement does not fluctuate wildly

Removal is no longer immediate or automatic

Visibility is now governed by normal ranking dynamics

**The domain has moved from trial to tenure—at the lowest level.**

This stage determines:

The domain\'s first stable positions in actual SERPs

Which queries the site will rank for

How frequently it will appear

In which countries it will be displayed

How strongly it competes vs. incumbents

How much traffic it receives

**Why Stability Matters More Than Position**

At Stage 10, **stability is the achievement.**

AI systems care less about where a domain appears and more about whether its appearance produces

predictable outcomes.

Erratic placement signals unresolved risk. Stable placement signals that earlier concerns have been

adequately addressed.**Only once stability is observed can competitive differentiation begin.**

**Core Mechanics Inside Baseline Ranking**

Baseline Ranking is governed by three major systems:

**A. Visibility Allocation Engine**

AI selects:

Which queries the site can safely serve

What rank positions it should receive initially

How often it should appear

In which geographies visibility should occur

How visibility should scale week by week

**This mirrors resource allocation**—AI controls visibility the way a bank controls credit extension:

cautiously at first.

**B. Competitive Positioning Model**

AI measures the domain against active competitors:

Authority

Depth

Clarity

Consistency

Accuracy

User-comprehension modeling

Long-form vs. short-form strengths

Global coverage

Freshness

Structural predictability

**Baseline ranking positions the site where it adds value without destabilizing the broader SERP**

**ecosystem.**

This often means ranking:

**On page 2--6 for mid-tail queries**

**On page 1--3 for long-tail queries**

**Occasionally on page 1 for ultra-long-tail queriesy p g g q**

These initial placements allow risk-free observation of real user behavior at scale.

**C. Human Behavior Scaling**

AI tests:

Whether positive Stage 9 behavior holds when exposure increases

Whether larger user groups behave consistently

Whether certain geographies react differently

Whether mobile users vs. desktop users show different outcomes

Whether young users vs. older users have different friction patterns

**If Stage 9 performance was the small-scale lab test, Stage 10 is the real-world pilot rollout.**

Success here earns promotion to Stage 11.

**How AI Systems Determine Baseline Placement**

Baseline placement is derived from:

Performance during Stage 9 experiments

Observed user comprehension

Absence of negative feedback loops

Predictable behavior across contexts

**The system is not optimizing for satisfaction or engagement. It is confirming safety under repetition.**

**First Contact with Human Comparison**

Stage 10 is the first point where domains experience direct comparison in a human-visible way.

Users may now see multiple sources side by side. They may choose one over another. They may ignore

some entirely.

**AI systems observe these interactions—but cautiously.**

At this stage, user preference is informative, not decisive.

**Baseline Does Not Mean Neutral**

Baseline placement is often misinterpreted as neutral or default.**It is not.**

Baseline ranking is an earned status that reflects accumulated trust, usability, and alignment.

Many domains never reach this stage, regardless of content volume or effort.

**Why Baseline Ranking Is Often Misread as Failure**

From a human perspective, Stage 10 can feel disappointing.

Visibility exists, but it is modest. Growth is slow. Competitors may appear dominant.

**This is because Stage 10 is not designed to reward excellence. It is designed to confirm reliability**

**under sustained exposure.**

The system is still watching.

**Why Stage 10 Is Necessary Before Major Ranking**

AI cannot jump from \"micro-tests\" to \"large-scale visibility.\"

Baseline ranking allows AI to:

Observe stable patterns over weeks, not minutes

Test user reactions under real volumes

Confirm SERP utility under competitive pressure

Prevent ranking cliffs or harmful knowledge surfacing

Ensure long-term viability of the domain

**Baseline ranking is like training wheels—the domain is active, but controlled.**

**What the System Continues to Monitor**

Once baseline ranking is established, **monitoring intensifies.**

AI systems observe:

Whether user behavior remains stable over time

Whether content updates introduce instability

Whether scale increases friction

Whether incentives begin to distort behavior

**Stage 10 is a proving ground.The Role of Query Dependence**

Baseline ranking is not global.

A domain may achieve stable placement for:

Narrow topics

Specific intents

Low-risk informational queries

\...while remaining absent elsewhere.

**This selectivity is intentional.**

The system expands exposure only where confidence exists.

**Failure Conditions That Prevent Progression to Stage 11**

A domain may be downgraded or restricted if AI sees:

**Failure 1: Unexpected Spikes in Bounce Rate**

**Problem:** Indicating misalignment with user expectations

**Real-world impact:**

A site performs well in Stage 9 micro-tests but experiences 60% bounce rates when exposure increases 10x

in Stage 10. Users arriving via mid-tail queries find content too specialized or not what they expected. AI

detects satisfaction degradation at scale and pauses expansion.

**Failure 2: Query Misassignment**

**Problem:** The site appears on queries where users expect different content types

**Real-world impact:**

An educational career resource ranks for job search queries. Users expect job listings and applications, not

educational guides. Behavioral signals show confusion (quick bounce, return-to-SERP, query

reformulation). AI removes site from those query types.

**Failure 3: Weak Performance vs. Entrenched Competitors**

**Problem:** Major incumbents consistently outperform it

**Real-world impact:**

A new site competes against Wikipedia, .gov sites, and established authorities. Despite being trusted, users

consistently choose familiar sources. Dwell time on the new site is 40% shorter than competitors. AImaintains low placement due to revealed preference.

**Failure 4: Satisfaction Degradation at Scale**

**Problem:** Stage 9 signals don\'t scale to broader audiences

**Real-world impact:**

Content performs excellently with niche technical audiences in Stage 9 but confuses general audiences in

Stage 10. Average scroll depth drops from 70% to 35%. Query reformulation increases. AI limits exposure

to specialized queries only.

**Failure 5: Mixed Signals Across Regions**

**Problem:** Performance varies wildly between countries

**Real-world impact:**

Site performs excellently in English-speaking markets but poorly in international markets due to

terminology, examples, or cultural assumptions. AI detects regional instability and restricts geographic

expansion.

**Failure 6: Inconsistent Structure Across Pages**

**Problem:** Newer or older pages differ significantly in tone or clarity

**Real-world impact:**

Original 100 pages maintain excellent structure and performance. Newer 200 pages use different templates,

varying content density, inconsistent terminology. AI detects structural drift and questions long-term

reliability.

**Failure here does not remove trust—it pauses growth.**

AI can retry Stage 10 multiple times.

**Success Conditions for Entering Stage 11**

A domain progresses to Stage 11 when:

**A. Behavior Quality Scores Remain Strong at Scale**

Solid dwell time

Low bounce rate

High scroll depth

Good content completion signals

Low query reformulation**B. Competitor Replacement Opportunities Appear**

If the domain consistently beats existing results

**C. The Domain Demonstrates Global Usefulness**

Especially for non-localized topics like careers

**D. Structural Consistency Remains Strong**

Users consistently receive predictable, uniform content

**E. Multi-Region Performance Is Stable**

The site works equally well in 5, 10, or 20 countries

**F. AI Detects Long-Term Value**

E.g., thousands of pages with similar structure & quality

When these elements align, AI prepares the site for \"Growth Visibility\"—the first stage where traffic can

materially increase.

**Why Some Domains Plateau at Stage 10**

Not all domains progress beyond baseline ranking.

Some remain reliable but undifferentiated. Others are safe but redundant. Still others lack the depth or

clarity required to outperform incumbents.

**Stage 10 is therefore not a guarantee of advancement.**

It is a holding pattern where long-term potential is evaluated.

**Baseline Ranking and Time**

Time remains a central factor.

AI systems require sustained observation before adjusting weight or preference.

Short-term performance spikes do not matter.

**Long-term behavioral consistency does.**

Stage 10 rewards patience.

**What Causes Regression from Stage 10**

Regression is possible.If a domain begins to:

Contradict itself

Drift in identity

Introduce misleading patterns

Degrade user comprehension

\...baseline ranking may erode.

**Regression is usually gradual, not abrupt—but it is real.**

**Output of Stage 10**

AI produces:

**A. Stable Visibility Map**

Where the domain ranks for baseline queries

**B. Traffic Baseline Estimate**

The first measurable, persistent human traffic patterns

**C. Competitive Fit Assessment**

How often the domain wins or loses against competitors

**D. Regional Performance Scores**

Visibility strength across geographies

**E. Promotion Readiness Score**

Probability that Stage 11 will succeed

**F. Behavioral Consistency Metrics**

Validation of sustained performance over time

Baseline ranking ends when AI concludes the domain is now safe for expanded visibility.

**What Success at Stage 10 Actually Means**

Passing Stage 10 means:

The domain has achieved durable, repeatable visibility

Removal now requires cause, not caution

User exposure is no longer experimental

The domain is now \"in the system\"

**This is the first stage where visibility can be reliably measured.What Stage 10 Does Not Do**

Stage 10 does not:

Confer authority

Ensure growth

Prioritize the domain

Protect against competition

Guarantee advancement to Stage 11

Those outcomes require further stages involving weighting and preference.

**Stage 10 as a Visibility Floor**

**Stage 10 establishes a floor, not a ceiling.**

Below it lies invisibility and experimentation.

Above it lies competition, preference, and authority.

Reaching the floor is difficult. Rising above it is harder.

**Relationship to Other Stages**

**Stage 9 → Stage 10**

Strong performance in Stage 9 advances to Stage 10. A domain progresses to Stage 10 if:

Stage 9 behavior quality scores cross thresholds

User satisfaction is demonstrably higher than competitors

The domain performs consistently across user types

Content resolves queries with clarity

Risk profile remains low

**Stage 10 → Stage 11**

Success in Stage 10 earns promotion to Stage 11. If Stage 10 was the training-wheels phase, **Stage 11 is the**

**point where the AI system removes its restrictions and lets the domain grow.**

**Stage 10 Failure Modes**

If problems emerge in Stage 10, AI reverts the domain to Stage 10 adjustments until issues resolve. AI canretry Stage 10 multiple times.

**Timeline**

Stage 10 is an extended observation and scaling period:

**TYPICAL STAGE 10 DURATIONS:**

**Minimum:** 3-6 months

Needed to observe stable patterns

Test scaling across queries

Validate multi-region performance

Confirm competitive positioning

**Average:** 6-12 months

Most sites spend this long in Stage 10

Gradual expansion of visibility

Progressive ranking improvements

Building toward Stage 11

**Extended:** 12-24+ months

Sites with inconsistent performance

Domains with regional variations

Sites needing template adjustments

Gradual competitive gains

**Duration:** Months (typically 6-12)

**Pass Rate:** Varies based on sustained performance consistency

**PROGRESSION INDICATORS:**

Ready for Stage 11 after:

Consistent behavior quality scores (3+ months)

Stable multi-region performance (6+ countries)

Competitive advantages demonstrated

Structural consistency maintained

Traffic baseline established

Risk profile remains low**Practical Implications**

**Understanding Your Initial Placement**

**Typical Stage 10 ranking patterns:**

**FOR LONG-TAIL QUERIES (very specific):**

Page 1-3 positions are common

Example: \"skills required for pediatric oncology nurse\"

Low competition, high specificity

Good opportunity for early wins

**FOR MID-TAIL QUERIES (moderately specific):**

Page 2-6 positions initially

Example: \"what does a nurse do\"

Higher competition, more established players

Gradual advancement based on performance

**FOR SHORT-TAIL QUERIES (broad):**

Rarely ranked initially or very low positions

Example: \"nursing\"

Dominated by major authorities

Stage 11 required for advancement here

**Optimization Strategies for Stage 10**

**1. MAINTAIN STRONG BEHAVIOR SIGNALS**

Optimize for sustained engagement:

Keep dwell time high across all ranked pages

Minimize bounce rates through intent matching

Encourage scroll depth with structured content

Reduce query reformulation with comprehensive answers

Monitor these metrics:

Average time on page (should be 2+ minutes for educational content)

Bounce rate (should be \<40% for matched intent)Scroll depth (should reach 70%+ for long content)

Return-to-SERP rate (should be \<30%)

**2. ENSURE COMPETITIVE ADVANTAGE**

Outperform visible competitors:

Provide more comprehensive coverage than alternatives

Use clearer structure than competitor pages

Maintain higher information density

Update content more frequently

Offer unique insights or frameworks

Competitive audit checklist: ☐ Your content is 2x deeper than top-ranking competitor

☐ Your structure is clearer and more scannable

☐ Your information is more current

☐ Your examples are more relevant

☐ Your page loads faster

**3. DEMONSTRATE GLOBAL CONSISTENCY**

Ensure multi-region performance:

Content works across cultures

Examples are internationally applicable

Terminology is globally understood

No region-specific dependencies

Mobile experience is excellent everywhere

Test across:

Different countries (at least 5-10)

Different devices (mobile vs desktop)

Different browsers

Different user ages/contexts

**4. MAINTAIN STRUCTURAL PREDICTABILITY**

Keep template consistency:

All pages use the same structure

Headings follow the same hierarchy

Content blocks appear in predictable order

Navigation is consistentNavigation is consistent

Internal linking patterns are stable

Warning signs to avoid:

New pages with different templates

Inconsistent heading structures

Varied content density

Unpredictable information architecture

Navigation changes

**5. SCALE CAREFULLY**

Don\'t destabilize your foundation:

Add new content gradually

Maintain quality standards consistently

Don\'t change successful templates

Monitor performance across all pages

Address problems quickly

Scaling best practices:

Add 5-10 new pages per month maximum

Test new content types in limited quantities

Maintain 95%+ template consistency

Keep core pages stable while expanding

Monitor behavioral signals on new pages

**What to Expect in Stage 10**

**TRAFFIC PATTERNS:**

**Early Stage 10 (Weeks 1-4):**

Very modest traffic (hundreds to low thousands)

Primarily long-tail queries

Highly variable day-to-day

Regional concentration in test markets

**Mid Stage 10 (Weeks 5-12):**Gradually increasing traffic (thousands)

Mid-tail queries begin appearing

More consistent patterns emerge

Geographic expansion visible

**Late Stage 10 (Weeks 13-24):**

Stable baseline traffic (tens of thousands potential)

Mix of long-tail and mid-tail

Predictable patterns established

Multi-region presence solid

**RANKING PATTERNS:**

**Long-tail queries:**

Initial: Page 1-3 positions

After 4 weeks: Some page 1 top positions

After 12 weeks: Dominant in long-tail category

**Mid-tail queries:**

Initial: Page 2-6 positions

After 4 weeks: Page 2-4 positions

After 12 weeks: Page 1-3 positions (if performing well)

**Short-tail queries:**

Initial: Rarely visible

After 4 weeks: Occasional page 5-10 appearances

After 12 weeks: Still limited (Stage 11 needed for growth)

**COMPETITIVE DYNAMICS:**

**Week 1-4: Observation**

AI watches how you perform vs established players

Limited direct competition

Focus on user satisfaction, not rankings

**Week 5-12: Positioning**

AI tests you against mid tier competitorsAI tests you against mid-tier competitors

Some query families shift toward you

Rankings become more stable

**Week 13-24: Validation**

AI confirms you\'re ready for growth

Consistent competitive performance

Preparation for Stage 11 expansion

**Common Stage 10 Mistakes to Avoid**

**MISTAKE 1: Celebrating too early**

Problem: Treating Stage 10 placement as \"success\"

Reality: Stage 10 is training wheels, not the destination

Solution: Focus on Stage 11 preparation, not current rankings

**MISTAKE 2: Changing winning formulas**

Problem: Modifying templates or content strategy prematurely

Reality: Consistency is being rewarded—don\'t break it

Solution: Keep successful patterns stable; test changes minimally

**MISTAKE 3: Aggressive scaling**

Problem: Adding hundreds of new pages quickly

Reality: Quality consistency matters more than quantity

Solution: Scale gradually; maintain rigorous quality standards

**MISTAKE 4: Neglecting behavioral signals**

Problem: Focusing only on rankings, not user engagement

Reality: Stage 11 progression depends on behavior, not position

Solution: Optimize for dwell time, scroll depth, low bounce rates

**MISTAKE 5: Inconsistent geographic performance**

Problem: Strong in one region, weak in others

Reality: Global consistency required for Stage 11

Solution: Ensure content works equally well across all markets**CV4Students Case Study: Baseline Ranking Illustration**

For a domain like CV4Students, Stage 10 might look like:

**RANKING PATTERNS:**

Long-tail career queries (Page 1-2):

\"skills required for pediatric oncology nurse\"

\"how to become a cardiovascular technologist\"

\"duties of a cloud security architect\"

Structured mid-tail queries (Page 2-4):

\"what does a nurse do\"

\"software engineer responsibilities\"

\"career guide for teachers\"

**TRAFFIC CHARACTERISTICS:**

Gaining measurable but modest human traffic

Primarily educational query traffic

Global distribution across 125+ countries

High engagement metrics

**BEHAVIORAL SIGNALS:**

Strong dwell time:

3,000-word comprehensive guides encourage reading

Average 3-5 minutes per page

Users consume substantial content

High scroll depth:

Structured sections guide progressive reading

70-80% scroll depth typical

Content remains valuable throughout

Low bounce rates:

Educational intent matches query intent

Comprehensive answers satisfy user needsComprehensive answers satisfy user needs

Minimal return-to-SERP behavior

**COMPETITIVE ADVANTAGES:**

Outperforming fragmented competitors:

Job boards provide shallow content

Career sites lack structure

CV4Students offers systematic depth

Consistent global performance:

125 countries reached

Content works across regions

No geographic performance variance

**RISK PROFILE:**

Maintaining low risk:

Educational intent maintained

Non-commercial classification advantage

No controversial content

Factually aligned with authorities

**SCALING CHARACTERISTICS:**

Scaling smoothly without destabilizing SERPs:

350+ pages with identical structure

Predictable user experience

Stable performance across all pages

These conditions would indicate strong readiness for Stage 11.

*(This remains illustrative, not evaluative.)*

**Why Stage 10 Is a Critical Inflection Point**

Many strategic errors occur here.

**Domains mistake baseline ranking for completion and shift behavior prematurely**—chasing

optimization, monetization, or scale.

h hif f d i h bili h bl d SThese shifts often undermine the very stability that enabled Stage 10.

AI systems notice.

**The Quiet Consequence of Stability**

Once baseline ranking is achieved, the domain\'s actions matter more.

Small changes have larger effects.

Errors propagate further.

Behavior is amplified.

**Stage 10 increases responsibility.**

**Stage 10 Success Checklist**

For successful Stage 10 progression:

**BEHAVIORAL PERFORMANCE:**

☐ Dwell time consistently 2+ minutes for educational content

☐ Bounce rate \<40% for matched-intent queries

☐ Scroll depth 70%+ for long-form content

☐ Return-to-SERP rate \<30%

☐ Low query reformulation (users find answers)

**COMPETITIVE POSITION:**

☐ Content depth exceeds top 3 competitors

☐ Structure clearer than alternatives

☐ Information more current than competitors

☐ Unique value proposition demonstrated

☐ Consistent wins against mid-tier competitors

**GLOBAL CONSISTENCY:**

☐ Performance stable across 5+ countries

☐ Mobile experience excellent everywhere

☐ No region-specific issues

☐ Content works across cultures

☐ Multi-device consistency maintained

**STRUCTURAL STABILITY:**

☐ 95%+ template consistency across all pages

☐ Predictable information architecture

☐ Stable heading hierarchies

☐ Consistent navigation patterns☐ Consistent navigation patterns

☐ No template drift in new pages

**SCALING DISCIPLINE:**

☐ New pages added gradually (5-10/month)

☐ Quality standards maintained

☐ No destabilization of SERPs

☐ Behavioral signals monitored on new pages

☐ Problems addressed quickly

If you can check all boxes consistently for 6+ months, Stage 11 advancement is likely.

**The Stage 10 Imperative**

**Stage 10 is where AI validates that Stage 9\'s promise scales to reality.**

Micro-impressions (Stage 9) prove concept. Baseline ranking (Stage 10) proves viability.

**Key validation questions:**

Do positive signals hold at 10x the traffic?

Does performance remain consistent across regions?

Can the site compete with established players?

Is the structure stable enough for growth?

Are users genuinely satisfied at scale?

**The sites that succeed in Stage 10:**

Maintained template consistency as they scaled

Kept behavior signals strong across all pages

Demonstrated clear competitive advantages

Worked equally well in multiple countries

Stayed focused on user value, not rankings

**The sites that stall in Stage 10:**

Changed successful formulas prematurely

Scaled too aggressively without quality control

Lost consistency across pages

Showed regional performance variations

Focused on rankings instead of user satisfaction

**Key Takeaway:** Stage 10 is the proving ground for Stage 11 growth. AI is watching whether your site canhandle visibility responsibly. Strong, consistent performance over 6-12 months earns the removal of training

wheels. Inconsistent performance keeps you in Stage 10 indefinitely.

**If Stage 10 was the training-wheels phase, Stage 11 is the point where the AI system removes its**

**restrictions and lets the domain grow.**

**The Standard of First Stability**

Stage 10 enforces a clear standard:

**If repeated exposure does not produce predictable, safe outcomes, stable ranking will not be**

**maintained.**

Only domains that meet this standard remain visible long enough to compete for authority.

**The Reality of Baseline Human Ranking**

Baseline ranking is conservative.

It is cautious.

It is deliberately unspectacular.

It reflects a system saying:

**\"This domain can now be shown regularly without causing harm.\"**

Nothing more. Nothing less.

---

## ACCESS AND SCOPE NOTICE

Detailed methodologies for AI visibility measurement, architectural frameworks, and diagnostic practices are maintained separately. This paper describes the structural gap — not the operational response.

Role definitions establish scope and responsibility at the time of publication. Certification standards, enforcement mechanisms, and governance requirements evolve as the AI visibility discipline matures.

Public documentation describes what is happening, not how to address it.

---

**Source:** The 11-Stage AI Visibility Lifecycle (v0.7) — A Framework for Understanding AI-Mediated Content Discovery

**Framework Developer:** Bernard Lynch, Founder of CV4Students.com, AI Visibility & Signal Mesh Architect, Developer of the 11-Stage AI Visibility Lifecycle | AI Visibility Architecture Group Limited | AIVisibilityArchitects.com

---

**License** This work is licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License (CC BY-NC-ND 4.0). To view a copy of this license, visit: https://creativecommons.org/licenses/by-nc-nd/4.0/

**Canonical Source** This Zenodo deposit is the canonical source for the AI Visibility Lifecycle framework. Related implementations: cv4students.com | aivisibilityarchitects.com

**Suggested Citation** Lynch, B. (2026). Stage 10 — Baseline Human Visibility: First Stable Search Placement (v0.7). Zenodo. https://doi.org/10.5281/zenodo.18514176
